\section*{Лекция 1. Наблюдение за случайной величиной X.}

Мы наблюдаем за случайной велчиной $X$ с функцией распределения $F_X(x, \theta)$. Мы проводим эксперимент $n$ раз и получаем значения $\{x_1, \ldots, x_n\}$. Где $\theta$ - некоторый параметр распределения (Пример: в распределении Пуассона - это $\lambda$).

\begin{definition}
    Основное предположение статистики:
    мы предполагаем, что в нашем эксперименте величины $\{x_1, \ldots, x_n\}$ \textbf{случайны}, \textbf{одинаково распределены} и \textbf{независимы}.
\end{definition}

Пускай у нас есть некоторое распределение:
\begin{table} [H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        $x_1$         & $x_2$         & $\ldots$ & $x_n$         \\
        \hline
        $\frac{1}{n}$ & $\frac{1}{n}$ & $\ldots$ & $\frac{1}{n}$ \\
        \hline
    \end{tabular}
\end{table}
Тогда мы можем ввести эмпирическую функцию распределения $F(x)^* = \frac{\nu}{n}$, где $\nu$ - число $x_i < x$, $\frac{v}{n}$ - частота частота события $\{X < x\}$.

Тогда мы можем записать математическое ожидание $E(X)$ и дисперсию $D(X)$: 
\begin{enumerate}
    \item $E(x) \approx \overline{x} = \sum\limits_{i = 1}^{n} x_i \frac{1}{n} $
    \item $D(X) \approx S^2 = \frac{1}{n} \sum\limits_{i = 1}^{n} (x_i - \overline{x})^2$
\end{enumerate}
$\mathbf{Z}$